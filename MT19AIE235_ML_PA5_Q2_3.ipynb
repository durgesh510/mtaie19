{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT19AIE235_ML_PA5_Q2.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIOTDDCeKCWqoF+HnsixCk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durgesh510/mtaie19/blob/master/MT19AIE235_ML_PA5_Q2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCMdtvRMzEiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "335d7f9a-bec3-4d42-808a-f239b2390471"
      },
      "source": [
        "#MT19AIE235\n",
        "# **Question 2.3.**\n",
        "# IMP - Setting the Data Set `path variable`\n",
        "\"\"\"\n",
        "Please update this path for **`training`** and **`validation`** dataset\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "p_train = \"/content/drive/My Drive/ML_Assign/PA5/GurNum/train\"                # Update this variable with the exact path for training dataset\n",
        "p_val = \"/content/drive/My Drive/ML_Assign/PA5/GurNum/val\"                    # Update this variable with the exact path for the val dataset\n",
        "\n",
        "# Importing the modules\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "\n",
        "\"\"\"# Neural Network\n",
        "\n",
        "Making reusable function:\n",
        "\n",
        "`get_nn_model()` - This function takes no. of hidden layers as input and returns the `pytorch nn` object with respective no. of hidden layers\n",
        "\n",
        "`get_criterion()` - This takes sets the respective loss function for the neural network \n",
        "\n",
        "`fit()` - This performs the training \n",
        "\n",
        "`model_accuracy()` - This computs the acccuracy of the model\n",
        "\"\"\"\n",
        "\n",
        "def get_nn_model(hidden_sizes):\n",
        "    if len(hidden_sizes) == 2:\n",
        "        model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(hidden_sizes[1], output_size),\n",
        "                            nn.LogSoftmax(dim=1))\n",
        "    elif len(hidden_sizes) == 3:\n",
        "        model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
        "                    nn.ReLU(),                              \n",
        "                    nn.Linear(hidden_sizes[2], output_size),\n",
        "                    nn.LogSoftmax(dim=1))\n",
        "    elif len(hidden_sizes) == 4:\n",
        "        model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
        "                    nn.ReLU(),     \n",
        "                    nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
        "                    nn.ReLU(),  \n",
        "                    nn.Linear(hidden_sizes[3], output_size),\n",
        "                    nn.LogSoftmax(dim=1))\n",
        "        \n",
        "    return model\n",
        "\n",
        "def get_criterion(l):\n",
        "\n",
        "    if l == \"NLLLoss\":\n",
        "        criterion = nn.NLLLoss()\n",
        "    elif l == \"MSELoss\":\n",
        "        criterion = nn.MSELoss()\n",
        "    elif l == \"SmoothL1Loss\":\n",
        "        criterion = nn.SmoothL1Loss()\n",
        "    elif l == \"CrossEntropyLoss\":\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    elif l == \"KLDivLoss\":\n",
        "        criterion = nn.KLDivLoss()\n",
        "    \n",
        "    return criterion\n",
        "\n",
        "def fit(model, lr, criterion):\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    time0 = time()\n",
        "    epochs = 15      \n",
        "    loss_history = dict()\n",
        "\n",
        "    for e in range(epochs):\n",
        "        running_loss = 0\n",
        "        for images, labels in trainloader:\n",
        "            # Flatten MNIST images into a 784 long vector\n",
        "            images = images[:, 2, :, :]\n",
        "            images = images.unsqueeze(1)\n",
        "            images = images.view(images.shape[0], -1)\n",
        "        \n",
        "            # Training pass\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            \n",
        "            #This is where the model learns by backpropagating\n",
        "            loss.backward()\n",
        "            \n",
        "            #And optimizes its weights here\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            loss_history[e] = running_loss/len(trainloader)\n",
        "            print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "\n",
        "    total_time_for_training = (time()-time0)/60\n",
        "\n",
        "    print(\"\\nTraining Time (in minutes) =\",total_time_for_training)\n",
        "\n",
        "    return model, total_time_for_training, loss_history\n",
        "\n",
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()\n",
        "\n",
        "def validation_one_sample(valloader, model):\n",
        "\n",
        "    images, labels = next(iter(valloader))\n",
        "\n",
        "    img = images[0].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "    view_classify(img.view(1, 28, 28), ps)\n",
        "\n",
        "def model_accuracy(valloader, model):\n",
        "\n",
        "    correct_count, all_count = 0, 0\n",
        "    \n",
        "    for images,labels in valloader:\n",
        "        images = images[:, 2, :, :]\n",
        "        images = images.unsqueeze(1)\n",
        "        for i in range(len(labels)):\n",
        "            img = images[i].view(1, 784)\n",
        "            with torch.no_grad():\n",
        "                logps = model(img)\n",
        "                \n",
        "            ps = torch.exp(logps)\n",
        "            probab = list(ps.numpy()[0])\n",
        "            pred_label = probab.index(max(probab))\n",
        "            true_label = labels.numpy()[i]\n",
        "            if(true_label == pred_label):\n",
        "                correct_count += 1\n",
        "            all_count += 1\n",
        "\n",
        "    acc = correct_count/all_count\n",
        "\n",
        "#     print(\"Number Of Images Tested =\", all_count)\n",
        "#     print(f\"Model Accuracy = {acc}\")\n",
        "\n",
        "    return acc\n",
        "\n",
        "\"\"\"# Loading the dataset\n",
        "\n",
        "loading the `Gurmukhi` dataset from the local google drive\n",
        "\"\"\"\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "                                transforms.Resize(28),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))\n",
        "                                ])\n",
        "\n",
        "trainset = datasets.ImageFolder(root=p_train, transform = preprocess)\n",
        "valset = datasets.ImageFolder(root=p_val, transform = preprocess)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=10, shuffle=True)\n",
        "\n",
        "\"\"\"# Model Training\n",
        "\n",
        "starting the training here. \n",
        "While working on this problem, many diff hyperparameters were tried but this configuration gave best model accuracy \n",
        "\n",
        "\n",
        "\n",
        "> `input_size` = 784\n",
        "\n",
        "> `hidden_sizes` = [128, 32]\n",
        "\n",
        "> `output_size` = 10\n",
        "\n",
        "> `learning rate`  = 0.009\n",
        "\n",
        "> `batch size` = 10\n",
        "\n",
        "> `epochs` = 15\n",
        "\n",
        "> `loss function` = \"CrossEntropyLoss\"\n",
        "\"\"\"\n",
        "\n",
        "loss_funcs = [\"CrossEntropyLoss\"]\n",
        "\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 32]\n",
        "output_size = 10\n",
        "lr = 0.009\n",
        "\n",
        "prams  = {\"total_time_for_training\": None,\n",
        "          \"loss_history\": None,\n",
        "          \"accuracy\": None}\n",
        "\n",
        "final_result_loss = {i: prams.copy() for i in loss_funcs}\n",
        "\n",
        "for c in loss_funcs:\n",
        "    \n",
        "    print(f\"For Loss Function : {c}\")\n",
        "    print(\"*****************************\")\n",
        "    model = get_nn_model(hidden_sizes)\n",
        "    criterion = get_criterion(c)\n",
        "    model, total_time_for_training, loss_history = fit(model, lr, criterion)\n",
        "    accuracy = model_accuracy(valloader, model)\n",
        "    print(\"**************************\")\n",
        "    print(f\"Model Accuracy = {accuracy}\")\n",
        "\n",
        "\n",
        "    final_result_loss[c][\"total_time_for_training\"] = total_time_for_training\n",
        "    final_result_loss[c][\"loss_history\"] = loss_history\n",
        "    final_result_loss[c][\"accuracy\"] = accuracy\n",
        "    print(\"********************************\")\n",
        "\n",
        "\"\"\"# (Optional) Testing with single sample from Validatation dataset\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "images, labels = next(iter(valloader))\n",
        "images = images[:, 2, :, :]\n",
        "images = images.unsqueeze(1)\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.numpy()[0])\n",
        "\n",
        "print(\"******************************\\n\")\n",
        "print(f\"Actual Lable(Digit)                    : {labels[0].item()}\")\n",
        "print(f\"Predicted Label(Digit) from the model  : {probab.index(max(probab))}\\n\")\n",
        "print(\"******************************\")\n",
        "\n",
        "view_classify(img.view(1, 28, 28), ps)\n",
        "\n",
        "\"\"\"# Final Configuration and Conclusion\n",
        "\n",
        "This is the best configuration which was fetching ~ 95 to 96 % of accuracy\n",
        "\n",
        "## **Final Configuration:**\n",
        "\n",
        "> `input_size` = 784\n",
        "\n",
        "> `hidden_sizes` = [128, 32]\n",
        "\n",
        "> `output_size` = 10\n",
        "\n",
        "> `learning rate`  = 0.009\n",
        "\n",
        "> `batch size` = 10\n",
        "\n",
        "> `epochs` = 15\n",
        "\n",
        "> `loss function` = \"CrossEntropyLoss\"\n",
        "\n",
        "## **Conclusion**:\n",
        "\n",
        "It is observed that the training was fast w.r.t to MNIST as the data set was small(1000 images) and \n",
        "the model was working well with small batch size, since there were not many data points, so small batch \n",
        "size helped to update the `weights` faster and it moves towards convergence quickly\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "For Loss Function : CrossEntropyLoss\n",
            "*****************************\n",
            "Epoch 0 - Training loss: 0.962945239432156\n",
            "Epoch 1 - Training loss: 0.13072049688082188\n",
            "Epoch 2 - Training loss: 0.050905083196703345\n",
            "Epoch 3 - Training loss: 0.01553155050438363\n",
            "Epoch 4 - Training loss: 0.0065989375583012586\n",
            "Epoch 5 - Training loss: 0.003062184632435674\n",
            "Epoch 6 - Training loss: 0.003262375245030853\n",
            "Epoch 7 - Training loss: 0.001606211549769796\n",
            "Epoch 8 - Training loss: 0.0012129621287749616\n",
            "Epoch 9 - Training loss: 0.0010559867554002266\n",
            "Epoch 10 - Training loss: 0.0009105051767983241\n",
            "Epoch 11 - Training loss: 0.0008092734142883273\n",
            "Epoch 12 - Training loss: 0.0007317485347994079\n",
            "Epoch 13 - Training loss: 0.000659662939615373\n",
            "Epoch 14 - Training loss: 0.0006200237570874378\n",
            "\n",
            "Training Time (in minutes) = 3.3099082986513775\n",
            "**************************\n",
            "Model Accuracy = 0.9550561797752809\n",
            "********************************\n",
            "******************************\n",
            "\n",
            "Actual Lable(Digit)                    : 0\n",
            "Predicted Label(Digit) from the model  : 0\n",
            "\n",
            "******************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'# Final Configuration and Conclusion\\n\\nThis is the best configuration which was fetching ~ 95 to 96 % of accuracy\\n\\n## **Final Configuration:**\\n\\n> `input_size` = 784\\n\\n> `hidden_sizes` = [128, 32]\\n\\n> `output_size` = 10\\n\\n> `learning rate`  = 0.009\\n\\n> `batch size` = 10\\n\\n> `epochs` = 15\\n\\n> `loss function` = \"CrossEntropyLoss\"\\n\\n## **Conclusion**:\\n\\nIt is observed that the training was fast w.r.t to MNIST as the data set was small(1000 images) and \\nthe model was working well with small batch size, since there were not many data points, so small batch \\nsize helped to update the `weights` faster and it moves towards convergence quickly\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}